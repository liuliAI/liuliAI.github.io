<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>liuliAI</title>
        <link>https://liuliai.github.io</link>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Fri, 19 Jul 2024 11:59:00 +0800</pubDate>
        <lastBuildDate>Fri, 19 Jul 2024 11:59:00 +0800</lastBuildDate>
        <item>
            <guid isPermalink="true">https://liuliai.github.io/2024/07/19/Cantor%EF%BC%9A%20Inspiring%20Multimodal%20Chain-of-Thought%20of%20MLLM/</guid>
            <title>Cantor：Inspiring Multimodal Chain-of-Thought of MLLM</title>
            <link>https://liuliai.github.io/2024/07/19/Cantor%EF%BC%9A%20Inspiring%20Multimodal%20Chain-of-Thought%20of%20MLLM/</link>
            <pubDate>Fri, 19 Jul 2024 11:59:00 +0800</pubDate>
            <description><![CDATA[ &lt;h2&gt;Cantor: Inspiring Multimodal Chain-of-Thought of MLLM&lt;/h2&gt;
&lt;p&gt;本文是论文&lt;a href=&#34;https://arxiv.org/abs/2404.16033&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;font color=&#34;LimeGreen&#34;&gt;Cantor: Inspiring Multimodal Chain-of-Thought of MLLM&lt;/font&gt;&lt;/strong&gt;&lt;/a&gt;的阅读笔记和个人理解，论文由厦门大学和腾讯优图实验室共同合作而成。探讨了一种多模态 CoT 框架，名为 Cantor，它具有感知决策架构，有效地集成了视觉上下文和逻辑推理来解决视觉推理任务。&lt;/p&gt;
&lt;p&gt;Cantor 的特点是感知 - 决策架构。Cantor 首先充当决策生成器，并集成视觉输入来分析图像和问题，确保与实际上下文更紧密地保持一致。此外，Cantor 利用 MLLM 的高级认知功能作为多方面的专家来获取更高层次的信息，从而增强 CoT 生成过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这种多模态思维链方法无需额外训练&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/image/Cantor-fig1.jpg&#34; alt=&#34; 决策生成中视觉信息的比较&#34;&gt;&lt;/p&gt;
&lt;h6&gt;（a） 决策生成中视觉信息的比较：由于图像不够清晰，询问GPT-3.5（没有视觉背景）会导致“确定幻觉”。Cantor（带字幕）通过字幕引入视觉背景，不会遇到这个问题。Cantor（带图像）更加精确，提高了任务分配的合理性。（b） 不同视觉工具的比较：传统方法中使用的低级专业感知工具只能获得基本数据。由MLLM代理的高级通用认知专家获得对象数关系，实现直接和后续推理。&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;但我感觉这个图的比较不太恰当，在多模态 CoT 领域，却拿 GPT-3.5 这种 LLM 来做比较，只询问烧杯最大刻度，缺乏图像信息当然无法正确回答了，为什么不使用 GPT-4V 或者 Gemini 等多模态模型进行对比呢，而且 Baseline 就应该使用图像字幕的形式，而不是说 Cantor 通过字幕引入了视觉语境，避免了决策幻觉。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;摘要&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;随着大型语言模型 （LLMs）的出现，通过思维链 （CoT）方法得到增强，视觉推理问题通常被分解为可管理的子任务，并用各种外部工具依次解决。然而，由于视觉信息不足和低级感知工具的局限性，无法提供全面推理所需的抽象摘要，这种范式面临着决策中潜在的 “决定性幻觉” 的挑战。我们认为，融合视觉上下文获取和逻辑推理对于解决视觉推理任务至关重要。本文深入研究了多模态 CoT 领域，以多模态大型语言模型 （MLLMs）及其认知能力解决复杂的视觉推理任务。为此，我们提出了一种创新的多模态 CoT 框架，称为 Cantor，其特点是感知 - 决策架构。Cantor 首先充当决策生成器，并集成视觉输入来分析图像和问题，确保与实际上下文更紧密地保持一致。此外，Cantor 利用 MLLM 的高级认知功能作为多方面的专家来获取更高层次的信息，从而增强 CoT 生成过程。我们广泛的实验证明了所提出的框架的有效性，表明在两个复杂的视觉推理数据集中，多模态 CoT 性能显着提高，而无需微调或地面真实原理。项目页面：&lt;br&gt;
&lt;a href=&#34;https://ggg0919.github.io/cantor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;font color=&#34;HotPink&#34;&gt;https://ggg0919.github.io/cantor/&lt;/font&gt;&lt;/strong&gt;&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/image/Cantor-fig2.jpg&#34; alt=&#34;Cantor概述和具体示例&#34;&gt;&lt;/p&gt;
&lt;h6&gt;Cantor概述和具体示例。Cantor通过决策生成器分析图像和问题，提供问题的原理分析，并提供模块选择和原因，以及具体的任务分配。随后，MLLM充当各种专家模块来执行子任务。最后，Cantor通过答案生成器进行综合和思考，提供最终答案。&lt;/h6&gt;
&lt;blockquote&gt;
&lt;p&gt;引言&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;随着大型语言模型 （LLMs）的发展，研究者开始采用思维链 （CoT）策略来提高模型在推理任务中的性能。CoT 模仿人类的渐进推理过程，通过构建一系列逻辑步骤来解决复杂的视觉推理问题，帮助模型提高他们的深度理解和分析能力。CoT 的有效性已在语言推理任务中得到广泛验证。最近，研究人员自然而然地将其应用扩展到了多模态域。视觉推理任务天生就适合于思维链 （CoT）方法。这些任务要求模型不仅要 “感知” 图像中的内容和上下文，还要 “理解” 这些视觉元素，以做出连贯的推理和决策。因此，多模态 CoT 的探索在研究界得到了显着扩展。大多数现有的多模态 CoT 方法分为两个阶段：决策生成和执行。1）决策生成。这是多模态 CoT 方法的第一步，涉及理解、分析和制定问题的推理计划。现有的确定方法包括将问题分解为子问题 、在图像中捕捉场景图 、查找相关图像的异同等  。他们试图在文本层面简化问题，或在视觉层面添加更多上下文信息。2）执行。在此阶段，模型执行由上一个确定阶段安排的特定操作。具体而言，该模型将规划转化为实际解决方案。现有的执行方法通常依赖于各种专门的 API 工具或视觉语言模型 （VLMs），前者强调任务执行的特殊性，后者强调任务执行的普遍性。虽然这些多模态 CoT 方法提高了视觉推理任务的性能，但仍存在局限性：首先，现有方法在做出决策时，往往直接将纯文本输入到 LLM 中，而不考虑视觉上下文。从直觉上讲，这增加了 LLM 对问题的发散性思维，但实际上，它可能导致 “确定幻觉”。如图 1（a）所示，如果问题本身与图像没有密切关系，而只是根据文本询问 “这个类测量的最高量是多少？”，则 LLM（GPT-3.5）不清楚 “这个类” 的具体含义。它会回答所提供的信息不足，并开始猜测 “类” 是指物理学中的度量还是编程中的类。这种感知的不确定性可能导致 LLM 做出与问题无关的决策，甚至是不正确的、误导性的后续执行，并导致完全不相关的答案。&lt;/p&gt;
&lt;p&gt;其次，在执行过程中，现有方法通常通过调用外部工具来执行任务，因为 MLLM 仍然无法解决众多的视觉推理任务。但这些工具大多是低级的视觉感知工具 （检测器、识别器、OCR 等），只能提取低级的视觉信息。如图 1（b）所示，在比较溶液中的粒子数时，它们仅提供粒子的位置，而无法推断出它们数量之间的关系等高级信息。他们进一步将这些低级线索输入到 LLM 中进行组织和总结 。当复杂的线索增加时，这无疑增加了 LLM 对长文本推理的负担。同时，使用许多外部工具，也增加了管道的复杂性。为了解决上述局限性，我们提出了一种新颖的多模态 CoT 框架 Cantor。在决策生成中，我们使 MLLM 或 LLM 在合唱中充当唱者，同时处理视觉和文本上下文以进行全面理解，然后将特定任务分配给由单个 MLLM 执行的 “专家”，以进行高级逻辑问题解决。具体来说，在决策生成过程中，我们详细分析了视觉信息在决策阶段的重要性。这包括有或没有视觉信息的确定质量，以及详细或简洁的视觉信息对确定的影响的差异。最终，我们得出结论，视觉信息在决策生成阶段至关重要。当我们使用 MLLM 模型 （如 Gemini）作为决策生成器时，我们直接将图像输入到模型中，以充分理解问题并对其进行深思熟虑。然而，当采用 LLM 模型 （如 GPT-3.5）时，我们发现提供更详细的图像标题更有利于理解问题。此外，决策生成器需要明确提供解释性决策，包括解决问题的策略、专家调用的原因以及每个专家的具体任务执行。因此，它指导 MLLM 充当量身定制的专家 （例如 ObjectQuant Locator、TextIntel Extractor、VisionIQAnalyst 和 ChartSense Expert），为流程中的子任务提供结论性答案。如图 1（a）所示，当使用 LLM 做出决定时，在详细的标题指导下，模型知道它要求烧杯的最大体积并做出正确的决定。当图像可供 MLLM 使用时，决策会更加清晰，也就是说，需要 VisionIQAnalyst 提取杯壁顶部的数字。在执行过程中，我们观察到 MLLM 是一种高级认知工具，在直接获取高级信息（例如，相对位置和数量）方面比获取低级视觉信息（如检测位置）性能更好。这种高级信息对于多模态 CoT 来说是优越的。Cantor 没有使用多个外部工具，而是通过不同的专家身份和任务说明将不同的任务分配给单个 MLLM，探索充当某些专家的 MLLM 的专业潜力。量身定做的专家直接提供高水平的专业信息，从而减轻了后续综合推理的负担。如图 1（b）所示，在比较绿色颗粒的浓度时，我们需要先比较两个瓶子中的颗粒数量。MLLM 充当 ObjectQuant 定位器，直接比较两个解决方案中的数量方差。与获取粒子位置相比，MLLM 更准确地获得数量关系的结果。该结果直接应用于最终答案的进一步推断。&lt;/p&gt;
&lt;p&gt;我们提出的框架 Cantor 在 ScinceQA 和 Mathvista 中均实现了 SOTA 结果。当 Gemini 用作决策生成器时，Cantor 分别获得 4.11% 和 5.9% 的精度增益。在 Cantor 中使用 GPT-3.5 还可以实现 2.24% 和 9.2% 的准确度增益。在我们所有的实验中，我们只使用一个 MLLM （Gemini）来扮演多个专家的角色，执行不同的子任务，有不同的要求。我们的贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了一个鼓舞人心的多模态 CoT 框架，名为 Cantor，它具有感知决策架构，有效地集成了视觉上下文和逻辑推理来解决视觉推理任务。&lt;/li&gt;
&lt;li&gt;我们利用 MLLM 的高级认知能力，充当多方面的专家，获取更高层次的信息并显着增强 CoT 的生成。&lt;/li&gt;
&lt;li&gt;我们在两个具有挑战性的基准测试中证明了 Cantor 的有效性，大大超过了现有的同行。&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liuliai.github.io/2024/07/17/MemoryBank%EF%BC%9AEnhancing%20Large%20Language%20Models%20with%20Long-Term%20Memory/</guid>
            <title>MemoryBank：Enhancing Large Language Models with Long-Term Memory</title>
            <link>https://liuliai.github.io/2024/07/17/MemoryBank%EF%BC%9AEnhancing%20Large%20Language%20Models%20with%20Long-Term%20Memory/</link>
            <pubDate>Wed, 17 Jul 2024 17:18:00 +0800</pubDate>
            <description><![CDATA[ &lt;h2&gt;MemoryBank：Enhancing Large Language Models with Long-Term Memory&lt;/h2&gt;
&lt;p&gt;本文是论文&lt;a href=&#34;https://arxiv.org/abs/2305.10250&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;font color=&#34;LimeGreen&#34;&gt;MemoryBank：Enhancing Large Language Models with Long-Term Memory&lt;/font&gt;&lt;/strong&gt;&lt;/a&gt;的阅读笔记和个人理解，论文来自 AAAI2024. 探讨了一种私人的长期记忆机制，利用持续互动随着时间推移能够适应用户个性的私人 LLM 系统。&lt;/p&gt;
&lt;p&gt;MemoryBank 建立在一个具有内存检索和更新机制的内存存储器上，能够总结过去的事件和用户的个性。通过不断的记忆更新不断进化，通过合成以前交互的信息，随着时间的推移理解和适应用户的个性，允许 LLM 根据经过的时间和记忆的相对重要性来忘记和强化记忆，从而提供更像人类的记忆机制和丰富的用户体验（需要持续互动，如私人伴侣系统、心理咨询和秘书协助）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;包容性强，对 ChatGPT 这样的封闭源代码模型和像 ChatGLM 这样的开放源代码模型方面是通用的&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MemoryBank 思想在作者源码上体现的很简单，就是他每次出现查询请求时，都会遍历一遍历史对话记录，然后当前查询的内容遗忘保留率&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;s+1&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.66666em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (有具体的数学模型，可以参考链接：&lt;a href=&#34;https://www.zhihu.com/question/364132423&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;font color=&#34;LimeGreen&#34;&gt;https://www.zhihu.com/question/364132423&lt;/font&gt;&lt;/strong&gt;&lt;/a&gt;，但是作者为了方便简化了)，作者的数学模型就是&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;e^{-\frac{t}{s}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.9393400000000001em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.9393400000000001em;&#34;&gt;&lt;span style=&#34;top:-3.363em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mopen nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mfrac&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8233428571428572em;&#34;&gt;&lt;span style=&#34;top:-2.656em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.2255000000000003em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;frac-line mtight&#34; style=&#34;border-bottom-width:0.049em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.384em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size3 size1 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.344em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter sizing reset-size3 size6&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，然后计算出这个遗忘强度值，然后用 random 随机数进行比较，当大于就删除这个，小于就保留，就实现了艾宾浩斯记忆曲线可以遗忘和增强记忆的功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/image/MemoryBank-fig1.jpg&#34; alt=&#34;MemoryBank概述&#34;&gt;&lt;/p&gt;
&lt;h6&gt;记忆存储器（§2.1）存储过去的对话、总结的事件和用户画像，而记忆更新机制（§2.3）更新记忆存储器。记忆检索（§2.2）召回相关记忆。SiliconFriend（第3节）是一个基于LLM的人工智能伴侣，基于MemoryBank。&lt;/h6&gt;
&lt;blockquote&gt;
&lt;p&gt;摘要&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大型语言模型（LLM）的革命性进步极大地重塑了我们与人工智能（AI）系统的互动，在一系列任务中表现出令人印象深刻的性能。尽管如此，一个显著的障碍仍然存在 —— 这些模型中缺乏长期记忆机制。这种不足在需要持续互动的情况下变得越来越明显，如私人伴侣系统、心理咨询和秘书协助。认识到长期记忆的必要性，我们提出了 MemoryBank，这是一种为 LLM 量身定制的新型记忆机制。记忆库使模型能够唤起相关记忆，通过不断的记忆更新不断进化，通过合成以前交互的信息，随着时间的推移理解和适应用户的个性。为了模仿拟人行为并选择性地保存记忆，记忆库引入了一种记忆更新机制，其灵感来自埃宾浩斯遗忘曲线理论。这种机制允许人工智能根据经过的时间和记忆的相对重要性来忘记和强化记忆，从而提供更像人类的记忆机制和丰富的用户体验。MemoryBank 在容纳像 ChatGPT 这样的封闭源代码模型和像 ChatGLM 这样的开放源代码模型方面是通用的。为了验证 MemoryBank 的有效性，我们通过在长期人工智能伴侣场景中创建一个名为 SiliconFriend 的基于 LLM 的聊天机器人来举例说明其应用。进一步调整心理逻辑对话数据，SiliconFriends 在互动中表现出更高的同理心和辨别力。实验包括对真实世界用户对话框的定性分析和对模拟对话框的定量分析。在后者中，ChatGPT 充当具有不同特征的多个用户，并生成涵盖广泛主题的长期对话上下文。我们的分析结果表明，配备 MemoryBank 的 Sili-conFriend 具有很强的长期陪伴能力，因为它可以提供有力的反应，回忆相关记忆，了解用户个性。这突出了 MemoryBank 的有效性&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引言&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大型语言模型（LLM）的出现，如 ChatGPT（OpenAI，2022）和 GPT-4（Open AI，2023），导致了从教育、医疗保健到客户服务和娱乐等各个行业的影响力不断增加。这些强大的人工智能系统展示了理解和产生类似人类反应的非凡能力。尽管 LLM 具有非凡的能力，但一个关键的局限性是缺乏长期记忆，这是类人沟通的一个重要方面，在需要持续互动的场景中尤其明显，如个人陪伴、心理咨询和秘书任务。人工智能中的长期记忆对于保持上下文理解、确保有意义的交互以及随着时间的推移理解用户行为至关重要。&lt;/p&gt;
&lt;p&gt;例如，个人人工智能同伴需要回忆过去的对话，以建立融洽的关系。在心理咨询中，人工智能可以通过了解用户的历史和过去的情绪状态来提供更有效的支持。同样，秘书人工智能需要记忆来进行任务管理和偏好识别。LLM 中长期记忆的缺失阻碍了它们的性能和用户体验。因此，开发具有改进记忆能力的人工智能系统以实现更无缝和个性化的交互至关重要。&lt;/p&gt;
&lt;p&gt;因此，我们引入了 MemoryBank，这是一种新颖的机制，旨在为 LLM 提供保持长期记忆和绘制用户画像的能力。MemoryBank 使 LLM 能够回忆历史互动，不断发展他们对上下文的理解，并根据过去的互动适应用户的个性，从而提高他们在长期互动场景中的表现。受 Ebbinghaus 遗忘曲线理论的启发，MemoryBank 进一步融入了一种动态记忆机制，该机制密切反映了人类的认知过程。这一机制使人工智能能够记忆、选择性遗忘，并根据逝去的时间加强记忆，提供更自然、更吸引人的用户体验。具体来说，MemoryBank 建立在一个具有内存检索和更新机制的内存存储器上，能够总结过去的事件和用户的个性。&lt;/p&gt;
&lt;p&gt;MemoryBank 是多功能的，因为它既可以容纳像 ChatGPT 这样的封闭源代码 LLM，也可以容纳像 ChapGLM（Zeng et al.，2022）或 BELLE（Yunjie Ji&amp;amp;Li，2023）这样的开源 LLM。&lt;/p&gt;
&lt;p&gt;为了举例说明 MemoryBank 的实际意义，我们开发了 SiliconFriend，这是一款基于 LLM 的人工智能伴侣聊天机器人，与这种创新的记忆机制相集成。SiliconFriend 旨在保留和参考过去的互动，增强 MemoryBank 在打造更具个性的人工智能伴侣方面的变革影响力。SiliconFriend 的一个显著特点是，它对从各种在线来源收集的 38k 个心理对话进行了调整，这使它能够表现出同理心、细心，并提供有用的指导，使它能够熟练地处理充满情感的对话。此外，SiliconFriend 的突出功能之一是通过总结过去的互动来了解用户的个性，这使其能够根据用户的个人特征定制反应，从而增强用户体验。此外，SiliconFriend 支持双语功能，可满足中英文交流用户的需求。这种多语言支持将其可访问性和可用性扩展到不同的用户组。SiliconFriend 通过两个开源模型 ChatGLM 和 BELLE 以及一个闭源模型 ChatGPT 实现，展示了 MemoryBank 在适应不同 LLM 方面的多功能性。&lt;/p&gt;
&lt;p&gt;为了评估 MemoryBank 的有效性，我们进行了包括定性和定量分析的评估，其中前者涉及真实世界的用户对话，后者采用模拟对话。为了进行定量分析，我们创建了一个由 10 天的对话组成的记忆库，这些对话涵盖了各种各样的主题。这些对话涉及 15 个不同性格的虚拟用户，其中 ChatGPT 扮演用户的角色，并根据他们的性格生成对话上下文。基于这种记忆存储，我们设计了 194 个探究性问题，以评估模型是否能够成功地回忆起相关记忆并提供适当的反应。实验结果展示了 SiliconFriend 在记忆回忆、提供移情陪伴和理解用户画像方面的能力。这些发现证实了 MemoryBank 在长期互动场景中显著提高 LLM 性能的潜力。在本文中，我们将主要贡献总结如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们介绍了 MemoryBank，这是一种新型的类人长期记忆机制，使 LLM 能够存储、回忆、更新记忆和绘制用户画像。&lt;/li&gt;
&lt;li&gt;我们通过 SiliconFriend 展示了 MemoryBank 的实际适用性，SiliconFriends 是一款基于 LLM 的人工智能伴侣，配备了 MemoryBank，并通过心理对话进行调整。它可以回忆过去的记忆，提供同理心的陪伴，并理解用户的行为。&lt;/li&gt;
&lt;li&gt;我们在三个关键方面展示了 MemoryBank 的可推广性：（1）适应开源和闭源 LLM；（2） 具备中英文双语能力；（3） 具有和不具有记忆遗忘机制的适用性。&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liuliai.github.io/2024/03/28/hello-world/</guid>
            <title>Hello World</title>
            <link>https://liuliai.github.io/2024/03/28/hello-world/</link>
            <pubDate>Thu, 28 Mar 2024 17:18:00 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;Welcome to &lt;a href=&#34;https://hexo.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&#34;https://hexo.io/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&#34;https://hexo.io/docs/troubleshooting.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&#34;https://github.com/hexojs/hexo/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#quick-start&#34;&gt;#&lt;/a&gt; Quick Start&lt;/h2&gt;
&lt;h3 id=&#34;create-a-new-post&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#create-a-new-post&#34;&gt;#&lt;/a&gt; Create a new post&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo new &lt;span class=&#34;token string&#34;&gt;&#34;My New Post&#34;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;a href=&#34;https://hexo.io/docs/writing.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Writing&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;run-server&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#run-server&#34;&gt;#&lt;/a&gt; Run server&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo server&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;a href=&#34;https://hexo.io/docs/server.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Server&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;generate-static-files&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#generate-static-files&#34;&gt;#&lt;/a&gt; Generate static files&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo generate&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;a href=&#34;https://hexo.io/docs/generating.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generating&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;deploy-to-remote-sites&#34;&gt;&lt;a class=&#34;markdownIt-Anchor&#34; href=&#34;#deploy-to-remote-sites&#34;&gt;#&lt;/a&gt; Deploy to remote sites&lt;/h3&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;span&gt;h&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;$ hexo deploy&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;More info: &lt;a href=&#34;https://hexo.io/docs/one-command-deployment.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deployment&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
